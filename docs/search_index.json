[["index.html", "2673 Regresion lineal Chapter 1 Análisis de regresión", " 2673 Regresion lineal A.J. Signes-Pastor Chapter 1 Análisis de regresión El análisis de regresión ocupa el corazón de la estadística. Es un termino amplio para una colección de metodologías para predecir la variable respuesta (también denominada dependiente o variable de desenlace (outcome variable) de una o más variables predictoras (también llamadas independientes o variables explicativas). En general, los análisis de regresión se pueden utilizar para identificar las variables explicativas que están relacionadas con la variable respuesta, para describir la forma de la asociación, y para determinar una ecuación de predicción de la variable respuesta con las variables explicativas. Por ejemplo, un analista deportista puede utilizar análisis de regresión para desarrollar una ecuación para predecir la cantidad de calorías que una persona quemará mientras hace ejercicio en la cinta. La variable respuesta es el número de calorías quemadas (calculado a partir de la cantidad de oxígeno consumido), y las variables predictoras podrían incluir la duración del ejercicio (minutos), porcentaje de tiempo al nivel cardiaco deseado de trabajo, velocidad (km/h), edad (años), genero y índice de masa corporal (IMC). Desde un punto de vista teórico, los análisis de regresión ayudan a contestar preguntas como: ¿Cuál es la relación entre la duración del ejercicio y las calorías quemadas? ¿Es lineal o curva? Por ejemplo, ¿tiene el ejercicio un menor impacto sobre la cantidad de calorías quemadas después de un determinado momento? ¿Como influye el esfuerzo del ejercicio (porcentaje de tiempo al nivel cardiaco deseado de trabajo, media velocidad)? ¿Son las relaciones encontradas las misma para personas jóvenes y adultas, hombres y mujeres, delgados y con sobrepeso? Desde un punto de vista práctico, los análisis de regression nos ayudaran a contestar preguntas como las siguientes: ¿Cuántas calorías puede un hombre de 30 años con un IMC de 28.7 quemar si anda 45 minutos a una media de velocidad de 6 km/h y se mantiene dentro del 80% de su nivel cardiaco de trabajo? ¿Cuál es el número mínimo de variables necesarias para predecir de forma precisa el número de calorías que una persona quemará cuando camine? ¿Cómo de precisa es la predicción? Tipos de regressión Uso típico Lineal simple Predecir una variable respuesta cuantitativa a partir de una variable explicativa cuantitativa. Polinomial Predecir una variable de respuesta cuantitativa a partir de una variable explicativa cuantitativa, donde la relación se modela como un polinomio de enésimo orden. Lineal múltiple Predecir una variable respuesta cuantitativa a partir de dos o más variables explicativas. Multinivel Predecir una variable de respuesta a partir de datos que tienen una estructura jerárquica (por ejemplo, estudiantes dentro de las aulas dentro de las escuelas). También se denominan modelos jerárquicos, anidados o mixtos. Multivariante Predecir más de una variable respuesta a partir de una o más variables explicativas. Logística Predecir una variable respuesta categórica a partir de una o más variables explicativas. Poisson Predecir una variable respuesta que represente recuentos de una o más variables explicativas. Riesgos proporcionales de Cox Predecir el tiempo hasta un evento (muerte, recaída) a partir de una o más variables explicativas. Series de tiempo Modelado de datos de series de tiempo con errores correlacionados. No lineales Predecir una variable respuesta cuantitativa a partir de una o más variables explicativas, donde la forma del modelo no es lineal. No paramétricas Predecir una variable respuesta cuantitativa a partir de una o más variables explicativas, donde la forma del modelo se deriva de los datos y no se especifica a priori. Robusta Predecir una variable respuesta cuantitativa a partir de una o más variables explicativas utilizando un enfoque que es resistente al efecto de observaciones influyentes. En esta clase nos centraremos en los métodos de regresión basados en el método de minimos cuadrados tales como la regresión linear simple y regresión múltiple. Los modelos basados en el método de mínimos cuadrados tienen la siguiente forma: \\(\\hat{Y}_{i}=\\hat{\\beta}_{0}+\\hat{\\beta}_{j} X_{ji}+...+\\hat{\\beta}_{k} X_{ki} \\quad i= 1 ... n\\) donde \\(n\\) es el número de observaciones y \\(k\\) es el número de variables predictoras. En esta ecuación \\(Y_{i}\\) es el valor a predecir de la variable dependiente para la observación \\(i\\) (especificamente, es la media estimada de la distribución \\(Y\\), condicionada por los valores predictivos). \\(X_{ji}\\) es el valor predictivo \\(j\\) para la observación \\(i\\). \\({\\beta}_{0}\\) es la intersección (el valor estimado de \\(Y\\) cuando todas las variables predictoras valen cero). \\({\\beta}_{j}\\) es el coeficiente de regresión para el predictor en posición \\(j\\) (representa la pendiente del cambio en \\(Y\\) por unidad de cambio en \\(X_{ji}\\)). Nuestro objetivo es seleccionar los parámetros del modelo (intersección y pendiente) que minimice la diferencia entre los valores de respuesta actual y los valores estimados por el modelo. Específicamente, los parámetros del modelo son seleccionados para minimizar la suma de cuadrados residuales (método de minimos cuadrados): \\(\\sum_{i=1}^{n}=(Y_i - \\hat{Y_i)}^{2}= \\sum_{i=1}^{n} (Y_i-\\hat{\\beta_0} + \\hat{\\beta_1} X_{ji} + ...+ \\hat{\\beta_k} X_{ki})^{2}=\\sum_{i=1}^{n} \\xi _{i}^{2}\\) Para interpretar los coeficientes del modelo por mínimos cuadrados se debe de satisfacer un número de asunciones estadísticas: Normalidad - Para los valores fijos de las variables independientes, la variable dependiente tiene una distribución normal. Independencia - Los valores de \\(Y_i\\) son independientes entre si. Linealidad - La variable dependiente está relacionada de forma lineal con la independiente. Homocedasticidad - La variable dependiente no varia con los niveles de las variables independientes (este se podría describir como varianza constante). Si las asunciones no se cumplen, los parámetros de significación e intervalo de confianza puede que no sean correctos. "],["regresión-lineal-simple..html", "Chapter 2 Regresión lineal simple. 2.1 Ejemplo base de datos “women” 2.2 Diagnosticos de la regresión", " Chapter 2 Regresión lineal simple. 2.1 Ejemplo base de datos “women” Acceso al código R Utilizaremos la base de datos preinstalada women. Esta base de datos proporciona la altura y peso de un grupo de 15 mujeres. library(ggplot2) help(women) fit &lt;- lm(weight ~ height, data=women) summary(fit) ## ## Call: ## lm(formula = weight ~ height, data = women) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.7333 -1.1333 -0.3833 0.7417 3.1167 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -87.51667 5.93694 -14.74 0.0000000017110819 *** ## height 3.45000 0.09114 37.85 0.0000000000000109 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.525 on 13 degrees of freedom ## Multiple R-squared: 0.991, Adjusted R-squared: 0.9903 ## F-statistic: 1433 on 1 and 13 DF, p-value: 0.00000000000001091 En la salida podemos observar la fórmula del modelo. El peso “weight” es la variable dependiente y altura “height” es la variable independiente o explicativa. El siguiente elemento son los residuos “Residuals”. Los residuos son básicamente la diferencia entre el valor actual observado y el valor respuesta estimado con el modelo. La sección de residuos muestra el valor mínimo, primer cuartil, mediana, tercer cuartil, y valor máximo. Con el fin de evaluar cómo de bueno es el ajuste del modelo nos fijamos en la simetría de la distribución. En nuestro caso la mediana/media de los residuos es cercana a 0, lo que sugiere que el modelo se ajusta bastante bien a los valores observados. La siguiente sección se refiere a los coeficientes del modelo. Teóricamente, en la regresión simple, los coeficientes son dos constantes desconocidas que representan la intersección y la pendiente de los términos del modelo lineal. La intersección y la pendiente son el resultado de generar la línea de ajuste lo más cercana posible a los puntos de nuestra base de datos. “Estimate” tiene dos filas. La primera es la intersección. La segunda file es la pendiente. En nuestro ejemplo la asociación entre el peso y la altura. La pendiente en nuestro ejemplo nos dice que por cada pulgada (in) en altura el peso aumenta 3.45 libras (1 lbs = 0.453 kg). “Standard Error” mide la cantidad media que los coeficientes estimados varia de la cantidad real media en nuestra variable respuesta. En una situación ideal queremos valores pequeños en relación con sus coeficientes. En nuestro ejemplo, observamos que por cada pulgada en altura el peso aumenta 3.45 libras. El error estándar se puede utilizar para obtener un estimador de la diferencia esperada en el caso que ejecutemos el modelo una y otra vez. En otras palabras, podemos decir que en peso estimado puede variar en 0.091 pulgadas. Los errores estándar también pueden utilizarse para calcular los intervalos de confianza y para evaluar estadísticamente la hipótesis de asociación entre la altura y peso existe. “t-value” es la medida de cuantas desviaciones estándar nuestros coeficientes se alejan de 0. Queremos que se alejen de 0, pues esto indicaría que podemos rechazar la hipótesis nula. Esto significa que podríamos confirmar la existencia de una asociación entre la altura y el peso. En nuestro ejemplo, el valor “t-statistic” están alejados de 0 y son grandes en relación con los errores standard, lo cual indica que la relación entre la altura y el peso existe. En general, los “t-value” se utilizan para determinar los “p-value”. “Pr(&gt;t)” se refiere a la probabilidad de observar un valor igual o más grande que t. Un “p-value” pequeño indica que es poco probable observar una relación entre la variable predictora (altura) y la variable respuesta (peso) debido al azar. Tradicionalmente, un “p-value” 5% o más pequeño como punto de corte. En nuestro ejemplo, el “p-value” son cercanos a 0. Un valor pequeño de “p-value” para la intersección y pendiente indica que podemos rechazar la hipótesis nula, lo que nos permite concluir que hay una relación entre la altura y el peso. El “Residual Standard Error” es una medida de la calidad de la regresión lineal. En teoría, en un modelo lineal se asume un término de error. Debido al término de error, no podemos predecir perfectamente la variable respuesta (peso) a partir de nuestra variable predictora (altura). En nuestro ejemplo, el peso estimado puede desviarse de la verdadera línea de regresión en aproximadamente 1.525 libras como media. En nuestro ejemplo el “Residual Standard Error” se ha calculado con 13 grados de libertad. De una forma simplista, los valores o grados de libertad son número de datos que se utilizaron en la estimación de los parámetros después de tener en cuenta dichos parámetros (restricción). En nuestro caso, tenemos 15 datos y 2 parámetros (intersección y pendiente). “Multiple R-squared, Adjusted R-squared” son medidas que nos proporcionan información de cómo de bueno es el ajuste. “Multiple R-squared” es una medida de la relación lineal entre nuestra variable predictora (altura) y nuestra variable respuesta (peso). Toma un valor entre 0 y 1 (un número cercano a 0 indica que la regresión no explica bien la variabilidad de la variable respuesta y un número cercano a 1 explica la variabilidad observada en la variable respuesta). En nuestro ejemplo, “Multiple R-squared” es 0.991 o 99% de la variabilidad encontrada en la variable respuesta (peso) se puede explicar con la variable predictora (altura). “Multiple R-squared” siempre aumenta con la inclusión de más variable predictoras en el modelo. Debido a esto se utiliza “Adjusted R-squared” que está ajustado por el número de variables consideradas. “F-Statistic” es un buen indicador para saber si existe una relación en la variable predictora y la variable respuesta. Si el “F-Statistic” se aleja de 1 es una buena señal. Sin embargo, cuánto más grande debe ser “F-Statistic” depende tanto del número de datos como del número de predictores. Generalmente, cuando el número de datos es grande, un estadístico F que sea solo un poco mayor que 1 ya es suficiente para rechazar la hipótesis nula. Si el número de puntos de datos es pequeño, se requiere un “F-Statistic” grande para poder determinar que puede haber una relación entre las variables de predicción y respuesta. En nuestro ejemplo, el “F-Statistic” es 1433, que es mucho mayor que 1 dado el tamaño de nuestros datos (Kabacoff, 2011). fit.res &lt;- fit$residuals mean(fit.res) ## [1] 0.00000000000000004808075 plot(women$height, fit.res) women$weight ## [1] 115 117 120 123 126 129 132 135 139 142 146 150 154 159 164 residuals(fit) ## 1 2 3 4 5 6 7 8 9 10 11 ## 2.41666667 0.96666667 0.51666667 0.06666667 -0.38333333 -0.83333333 -1.28333333 -1.73333333 -1.18333333 -1.63333333 -1.08333333 ## 12 13 14 15 ## -0.53333333 0.01666667 1.56666667 3.11666667 #par(mfrow=c(1,1)) plot(women$height,women$weight, xlab=&quot;Height (in inches)&quot;, ylab=&quot;Weight (in pounds)&quot;) abline(fit) library(ggplot2) women$predicted &lt;- predict(fit) ggplot(women, aes(x = height, y = weight)) + geom_smooth(method = &quot;lm&quot;, se = FALSE, color = &quot;lightgrey&quot;) + geom_segment(aes(xend = height, yend = predicted), alpha = .2) + geom_point() + geom_point(aes(y = predicted), shape = 1) + theme_bw() ## `geom_smooth()` using formula = &#39;y ~ x&#39; Con la información generada se puede predecir que la ecuación es: \\(\\hat{weight} = -87.52 + 3.45 x height\\) Una altura de 0 es imposible, por lo tanto, es complicado darle una interpretación a la intersección. La intersección en este caso es solamente un constante de ajuste. De la columna Pr(&gt;|t|), podemos ver que el coeficiente de regresión (3.45) es significativamente diferente de cero (p &lt; 0.001) e indica que hay un incremento esperado de 3.45 libra de peso por cado 1 pulgada de aumento en la altura. La multiple “R-squared” (0.991) indica que el modelo explica el 99.1% de la varianza en pesos. El error residual estándar (1.53 libra) se puede interpretar como la media de error en el peso estimado por la altura usando el presente modelo. Podemos observar que los residuales más grande tiene lugar para las alturas más bajas y altas. 2.2 Diagnosticos de la regresión De momento no sabemos si el modelo generado es adecuado. Hay que tener en cuenta que los parámetros de la regresión dependen del grado con el que se cumplen las asunciones estadísticas de los métodos de mínimos cuadrados. fit &lt;- lm(weight ~ height, data=women) #par(mfrow=c(2,2)) plot(fit) Para entender los gráficos generados, hay que tener en cuenta las asunciones para los modelos de mínimos cuadrados: Normalidad: si la variable dependiente se distribuye normalmente para un conjunto fijo de valores predictores, entonces los valores residuales deben distribuirse normalmente con una media de 0. La gráfica de QQ normal es una gráfica de probabilidad de los residuos estandarizados frente a los valores que se esperaría bajo normalidad. Si ha cumplido con la suposición de normalidad, los puntos de este gráfico deben estar en la línea recta de 45 grados. Como no es así, claramente ha violado ligeramente supuesto de normalidad. Independencia: no se puede saber si los valores de las variables dependientes son independientes. Se debe de conocer cómo se recogieron los datos. No hay ninguna razón a priori para creer que el peso de una mujer influye en el peso de otra. Si se incluyeran datos de una misma familia, es posible que fuera necesario ajustar por el supuesto de independencia. Linealidad: si la variable dependiente está relacionada linealmente con las variables independientes, no debe haber una relación sistemática entre los residuos y los valores estimados (“Residuals vs Fitted”). En otras palabras, el modelo debe capturar toda la varianza sistemática presente en los datos, sin dejar nada más que ruido aleatorio. En el gráfico de Residuos vs. Ajustado, verá una clara evidencia de una relación curva, lo que sugiere que es posible que desee agregar un término cuadrático a la regresión. Homoscedasticidad: si ha cumplido con el supuesto de varianza constante, los puntos en el gráfico Escala-Ubicación (Scale-Location) deben ser una banda aleatoria alrededor de una línea horizontal. Parece cumplir con esta suposición. Finalmente, el gráfico de Residuals vs. Leverage proporciona información sobre las observaciones individuales que quizás desee atender. El gráfico identifica valores atípicos, puntos de influciencia alta y observaciones influyentes. Específicamente: Un valor atípico es una observación que no se predice bien mediante el modelo de regresión ajustado (es decir, tiene un gran residuo positivo o negativo). Una observación con un valor de influencia alto tiene una combinación inusual de valores de predicción. Es decir, es un valor atípico en el espacio de predicción. El valor de la variable dependiente no se usa para calcular el la influencia de una observación. Una observación influyente es una observación que tiene un impacto desproporcionado en la determinación de los parámetros del modelo. Las observaciones influyentes se identifican mediante una estadística llamada distancia de Cook o D. de Cook. "],["regresión-multiple.html", "Chapter 3 Regresión multiple 3.1 Ejemplo base de datos “state.x77” 3.2 Diagnostico de la regresión", " Chapter 3 Regresión multiple 3.1 Ejemplo base de datos “state.x77” Acceso al código R Cuando hay más de una variable predictora, la regresión linear simple se convierte en regresión lineal múltiple. La regresion multiple se utiliza para el control de factores de confusión. Utilizaremos la base de datos preinstalada state.x77 como ejemplo. Esta base de datos tiene información sobre población, situación económica, tasa de alfabetismo, tasa de asesinatos, y tasa de graduación en instituto para los 50 Estados de USA en 1977. Para más información sobre la base de datos se puede utilizar help(state.x77). Imagínate que queremos explorar la relación entre la tasa de asesinatos y otras características de los estados incluyendo la población, tasa de alfabetismo, salario medio, y nivel de congelación (numero medio de días con temperaturas de congelación) help(&quot;state.x77&quot;) states &lt;- as.data.frame(state.x77[,c(&quot;Murder&quot;, &quot;Population&quot;, &quot;Illiteracy&quot;, &quot;Income&quot;, &quot;Frost&quot;)]) Un buen primer paso en regresión múltiple es examinar la relación entre pareja de variables. cor(states, method = &quot;pearson&quot;) ## Murder Population Illiteracy Income Frost ## Murder 1.0000000 0.3436428 0.7029752 -0.2300776 -0.5388834 ## Population 0.3436428 1.0000000 0.1076224 0.2082276 -0.3321525 ## Illiteracy 0.7029752 0.1076224 1.0000000 -0.4370752 -0.6719470 ## Income -0.2300776 0.2082276 -0.4370752 1.0000000 0.2262822 ## Frost -0.5388834 -0.3321525 -0.6719470 0.2262822 1.0000000 library(car) scatterplotMatrix(states, spread=FALSE, smoother.args=list(lty=2), main=&quot;Scatter Plot Matrix&quot;) 3.2 Diagnostico de la regresión states &lt;- as.data.frame(state.x77[,c(&quot;Murder&quot;, &quot;Population&quot;, &quot;Illiteracy&quot;, &quot;Income&quot;, &quot;Frost&quot;)]) fit &lt;- lm(Murder ~ Population + Illiteracy + Income + Frost, data=states) #par(mfrow=c(2,2)) summary(fit) ## ## Call: ## lm(formula = Murder ~ Population + Illiteracy + Income + Frost, ## data = states) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.7960 -1.6495 -0.0811 1.4815 7.6210 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.23456341 3.86611474 0.319 0.7510 ## Population 0.00022368 0.00009052 2.471 0.0173 * ## Illiteracy 4.14283659 0.87435319 4.738 0.0000219 *** ## Income 0.00006442 0.00068370 0.094 0.9253 ## Frost 0.00058131 0.01005366 0.058 0.9541 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.535 on 45 degrees of freedom ## Multiple R-squared: 0.567, Adjusted R-squared: 0.5285 ## F-statistic: 14.73 on 4 and 45 DF, p-value: 0.00000009133 plot(fit) Los supuestos del modelo parecen estar bien satisfechos, con la excepción de que Nevada es un valor atípico. "],["caso-práctico.html", "Chapter 4 Caso práctico 4.1 NHANES 4.2 Metales y crecimiento", " Chapter 4 Caso práctico 4.1 NHANES NHANES Web La Encuesta Nacional de Examen de Salud y Nutrición (NHANES) es un programa de estudios diseñado para evaluar el estado de salud y nutrición de adultos y niños en los Estados Unidos. La encuesta es única porque combina entrevistas y exámenes físicos. NHANES es un programa principal del Centro Nacional de Estadísticas de Salud (NCHS). NCHS es parte de los Centros para el Control y la Prevención de Enfermedades (CDC) y tiene la responsabilidad de producir estadísticas vitales y de salud para la Nación. El programa NHANES comenzó a principios de la década de 1960 y se ha realizado como una serie de encuestas centradas en diferentes grupos de población o temas de salud. En 1999, la encuesta se convirtió en un programa continuo que tiene un enfoque cambiante en una variedad de medidas de salud y nutrición para satisfacer las necesidades emergentes. La encuesta examina una muestra representativa a nivel nacional de unas 5.000 personas cada año. Estas personas se encuentran en condados de todo el país, 15 de los cuales son visitados cada año. La entrevista NHANES incluye preguntas demográficas, socioeconómicas, dietéticas y relacionadas con la salud. El componente de examen consta de mediciones médicas, dentales y fisiológicas, así como pruebas de laboratorio administradas por personal médico altamente capacitado. Los resultados de esta encuesta se utilizan para determinar la prevalencia de las principales enfermedades y los factores de riesgo de las enfermedades. La información se utiliza para evaluar el estado nutricional y su asociación con la promoción de la salud y la prevención de enfermedades. Los hallazgos de NHANES también son la base de los estándares nacionales para medidas como la altura, el peso y la presión arterial. Los datos de esta encuesta se utilizan en estudios epidemiológicos e investigaciones en ciencias de la salud, que ayudarán a desarrollar políticas sólidas de salud pública, dirigir y diseñar programas y servicios de salud y ampliar el conocimiento de la salud para la Nación. 4.2 Metales y crecimiento (Signes-Pastor et al., 2021) Acceso artículo Acceso al código R library(here) #install.packages(&quot;skim&quot;) data &lt;- read.csv(here(&quot;data&quot;, &quot;DATA_Final.csv&quot;)) dim(data) head(data) skim(data) # Análisis descriptivo de todas las variables. Variables description Body measures - 2013-14 https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/BMX_H.htm Body measures - 2015-16 https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/BMX_I.htm Variables de exposición data$ln_LBDPFL &lt;- log(data$LBDPFL) data$ln_LBXBMN &lt;- log(data$LBXBMN) data$ln_LBXBPB &lt;- log(data$LBXBPB) data$ln_LBXBSE &lt;- log(data$LBXBSE) data$ln_LBXTHG &lt;- log(data$LBXTHG) data$iqrFl &lt;- data$ln_LBDPFL/IQR(data$ln_LBDPFL) data$iqrMn &lt;- data$ln_LBXBMN/IQR(data$ln_LBXBMN) data$iqrPb &lt;- data$ln_LBXBPB/IQR(data$ln_LBXBPB) data$iqrSe &lt;- data$ln_LBXBSE/IQR(data$ln_LBXBSE) data$iqrHg &lt;- data$ln_LBXTHG/IQR(data$ln_LBXTHG) Selección cofactores data$calories &lt;- as.numeric(data$DR1TKCAL) data$INDFMPIR_ts &lt;- factor(data$INDFMPIR_ts_low.high, levels = c(&quot;low&quot;,&quot;high&quot;), labels = c(0,1)) data$sex &lt;- factor(data$RIAGENDR, levels = c(1,2), labels = c(0,1)) data$age &lt;- as.numeric(data$RIDAGEYR) data$race &lt;- as.factor(data$RIDRETH3.ts) data$smoke &lt;- as.factor(data$SMD460.ts) data$activityscore data$sch_activityscore Flúor (F) BMI - Body Mass Index Multiple_BMXBMI &lt;- lm(data$BMXBMI ~ (data$iqrFl) + (data$iqrMn) + (data$iqrPb) + (data$iqrSe) + (data$iqrHg) + data$calories + data$sex + data$INDFMPIR_ts + data$age + data$smoke + data$activityscore + data$sch_activityscore + data$race) cft &lt;- summary(Multiple_BMXBMI) round(cft$coefficients[2,1],2); round(confint(Multiple_BMXBMI), 2)[2,] ## [1] 0 ## 2.5 % 97.5 % ## -0.24 0.25 Altura en posición de pie - standing height Multiple_BMXHT &lt;- lm(data$BMXHT ~ (data$iqrFl) + (data$iqrMn) + (data$iqrPb) + (data$iqrSe) +(data$iqrHg) + data$calories + data$sex + data$INDFMPIR_ts + data$age + data$smoke + data$activityscore + data$sch_activityscore + data$race) cft &lt;- summary(Multiple_BMXHT) round(cft$coefficients[2,1],2); round(confint(Multiple_BMXHT),2) [2,] ## [1] 0 ## 2.5 % 97.5 % ## -0.42 0.41 Circumferencia de cintura - Waist circumference Multiple_BMXWAIST &lt;- lm(data$BMXWAIST ~ (data$iqrFl) + (data$iqrMn) + (data$iqrPb) + (data$iqrSe) + (data$iqrHg) + data$calories + data$sex + data$INDFMPIR_ts + data$age + data$smoke + data$activityscore + data$sch_activityscore + data$race) cft &lt;- summary(Multiple_BMXWAIST) round(cft$coefficients[2,1],2); round(confint(Multiple_BMXWAIST), 2) [2,] ## [1] 0.1 ## 2.5 % 97.5 % ## -0.56 0.76 Longitud del brazo superior - Upper arm length Multiple_BMXARML &lt;- lm(data$BMXARML ~ (data$iqrFl) + (data$iqrMn) + (data$iqrPb) + (data$iqrSe) + (data$iqrHg) + data$calories + data$sex + data$INDFMPIR_ts + data$age + data$smoke + data$activityscore + data$sch_activityscore + data$race) cft &lt;- summary(Multiple_BMXARML) round(cft$coefficients[2,1],2); round(confint(Multiple_BMXARML), 2)[2,] ## [1] -0.04 ## 2.5 % 97.5 % ## -0.16 0.09 Plomo (Pb) BMI - Body Mass Index Multiple_BMXBMI &lt;- lm(data$BMXBMI ~ (data$iqrPb) + (data$iqrMn) + (data$iqrFl) + (data$iqrSe) + (data$iqrHg) + data$calories + data$sex + data$INDFMPIR_ts + data$age + data$smoke + data$activityscore + data$sch_activityscore + data$race) cft &lt;- summary(Multiple_BMXBMI) round(cft$coefficients[2,1],2); round(confint(Multiple_BMXBMI), 2)[2,] ## [1] -0.47 ## 2.5 % 97.5 % ## -0.72 -0.21 Altura en posición de pie - standing height Multiple_BMXHT &lt;- lm(data$BMXHT ~ (data$iqrPb) + (data$iqrMn) + (data$iqrFl) + (data$iqrSe) + (data$iqrHg) + data$calories + data$sex + data$INDFMPIR_ts + data$age + data$smoke + data$activityscore + data$sch_activityscore + data$race) cft &lt;- summary(Multiple_BMXHT) round(cft$coefficients[2,1],2); round(confint(Multiple_BMXHT),2)[2,] ## [1] -0.7 ## 2.5 % 97.5 % ## -1.13 -0.27 Circumferencia de cintura - Waist circumference Multiple_BMXWAIST &lt;- lm(data$BMXWAIST ~ (data$iqrPb) + (data$iqrMn) + (data$iqrFl) + (data$iqrSe) +(data$iqrHg) + data$calories + data$sex + data$INDFMPIR_ts + data$age + data$smoke + data$activityscore + data$sch_activityscore + data$race) cft &lt;- summary(Multiple_BMXWAIST) round(cft$coefficients[2,1],2); round(confint(Multiple_BMXWAIST), 2)[2,] ## [1] -1.29 ## 2.5 % 97.5 % ## -1.97 -0.61 Longitud del brazo superior - Upper arm length Multiple_BMXARML &lt;- lm(data$BMXARML ~ (data$iqrPb) + (data$iqrMn) + (data$iqrFl) + (data$iqrSe) + (data$iqrHg) + data$calories + data$sex + data$INDFMPIR_ts + data$age + data$smoke + data$activityscore + data$sch_activityscore + data$race) cft &lt;- summary(Multiple_BMXARML) round(cft$coefficients[2,1],2); round(confint(Multiple_BMXARML), 2)[2,] ## [1] -0.24 ## 2.5 % 97.5 % ## -0.36 -0.11 Manganeso (Mn) BMI - Body Mass Index Multiple_BMXBMI &lt;- lm(data$BMXBMI ~ (data$iqrMn) + (data$iqrPb) + (data$iqrFl) + (data$iqrSe) + (data$iqrHg) + data$calories + data$sex + data$INDFMPIR_ts + data$age + data$smoke + data$activityscore + data$sch_activityscore + data$race) cft &lt;- summary(Multiple_BMXBMI) round(cft$coefficients[2,1],2); round(confint(Multiple_BMXBMI), 2)[2,] ## [1] 0.88 ## 2.5 % 97.5 % ## 0.59 1.18 Altura en posición de pie - standing height Multiple_BMXHT &lt;- lm(data$BMXHT ~ (data$iqrMn) + (data$iqrPb) + (data$iqrFl) + (data$iqrSe) + (data$iqrHg) + data$calories + data$sex + data$INDFMPIR_ts + data$age + data$smoke + data$activityscore + data$sch_activityscore + data$race) cft &lt;- summary(Multiple_BMXHT) round(cft$coefficients[2,1],2); round(confint(Multiple_BMXHT),2)[2,] ## [1] 0.7 ## 2.5 % 97.5 % ## 0.21 1.19 Circumferencia de cintura - Waist circumference Multiple_BMXWAIST &lt;- lm(data$BMXWAIST ~ (data$iqrMn) + (data$iqrPb) + (data$iqrFl) + (data$iqrSe) + (data$iqrHg) + data$calories + data$sex + data$INDFMPIR_ts + data$age + data$smoke + data$activityscore + data$sch_activityscore + data$race) cft &lt;- summary(Multiple_BMXWAIST) round(cft$coefficients[2,1],2); round(confint(Multiple_BMXWAIST), 2)[2,] ## [1] 2.47 ## 2.5 % 97.5 % ## 1.69 3.25 Longitud del brazo superior - Upper arm length Multiple_BMXARML &lt;- lm(data$BMXARML ~ (data$iqrMn) + (data$iqrPb) + (data$iqrFl) + (data$iqrSe) +(data$iqrHg) + data$calories + data$sex + data$INDFMPIR_ts + data$age + data$smoke + data$activityscore + data$sch_activityscore + data$race) cft &lt;- summary(Multiple_BMXARML) round(cft$coefficients[2,1],2); round(confint(Multiple_BMXARML), 2)[2,] ## [1] 0.2 ## 2.5 % 97.5 % ## 0.06 0.35 Mercurio (Hg) BMI - Body Mass Index Multiple_BMXBMI &lt;- lm(data$BMXBMI ~ (data$iqrHg) + (data$iqrPb) + (data$iqrFl) + (data$iqrSe) +(data$iqrMn) + data$calories + data$sex + data$INDFMPIR_ts + data$age + data$smoke + data$activityscore + data$sch_activityscore + data$race) cft &lt;- summary(Multiple_BMXBMI) round(cft$coefficients[2,1],2); round(confint(Multiple_BMXBMI), 2)[2,] ## [1] -0.05 ## 2.5 % 97.5 % ## -0.33 0.23 Altura en posición de pie - standing height Multiple_BMXHT &lt;- lm(data$BMXHT ~ (data$iqrHg) + (data$iqrPb) + (data$iqrFl) + (data$iqrSe) + (data$iqrMn) + data$calories + data$sex + data$INDFMPIR_ts + data$age + data$smoke + data$activityscore + data$sch_activityscore + data$race) cft &lt;- summary(Multiple_BMXHT) round(cft$coefficients[2,1],2); round(confint(Multiple_BMXHT),2)[2,] ## [1] -0.5 ## 2.5 % 97.5 % ## -0.97 -0.02 Circumferencia de cintura - Waist circumference Multiple_BMXWAIST &lt;- lm(data$BMXWAIST ~ (data$iqrHg) + (data$iqrPb) + (data$iqrFl) + (data$iqrSe) + (data$iqrMn) + data$calories + data$sex + data$INDFMPIR_ts + data$age + data$smoke + data$activityscore + data$sch_activityscore + data$race) cft &lt;- summary(Multiple_BMXWAIST) round(cft$coefficients[2,1],2); round(confint(Multiple_BMXWAIST), 2)[2,] ## [1] -0.2 ## 2.5 % 97.5 % ## -0.95 0.55 Longitud del brazo superior - Upper arm length Multiple_BMXARML &lt;- lm(data$BMXARML ~ (data$iqrHg) + (data$iqrPb) + (data$iqrFl) + (data$iqrSe) + (data$iqrMn) + data$calories + data$sex + data$INDFMPIR_ts + data$age + data$smoke + data$activityscore + data$sch_activityscore + data$race) cft &lt;- summary(Multiple_BMXARML) round(cft$coefficients[2,1],2); round(confint(Multiple_BMXARML), 2)[2,] ## [1] -0.13 ## 2.5 % 97.5 % ## -0.27 0.01 Selenium (Se) BMI - Body Mass Index Multiple_BMXBMI &lt;- lm(data$BMXBMI ~ (data$iqrSe) + (data$iqrPb) + (data$iqrFl) + (data$iqrHg) +(data$iqrMn) + data$calories + data$sex + data$INDFMPIR_ts + data$age + data$smoke + data$activityscore + data$sch_activityscore + data$race) cft &lt;- summary(Multiple_BMXBMI) round(cft$coefficients[2,1],2); round(confint(Multiple_BMXBMI), 2)[2,] ## [1] -0.17 ## 2.5 % 97.5 % ## -0.44 0.09 Altura en posición de pie - standing height Multiple_BMXHT &lt;- lm(data$BMXHT ~ (data$iqrSe) + (data$iqrPb) + (data$iqrFl) + (data$iqrHg) +(data$iqrMn) + data$calories + data$sex + data$INDFMPIR_ts + data$age + data$smoke + data$activityscore + data$sch_activityscore + data$race) cft &lt;- summary(Multiple_BMXHT) round(cft$coefficients[2,1],2); round(confint(Multiple_BMXHT),2)[2,] ## [1] -0.2 ## 2.5 % 97.5 % ## -0.65 0.25 Circumferencia de cintura - Waist circumference Multiple_BMXWAIST &lt;- lm(data$BMXWAIST ~ (data$iqrSe) + (data$iqrPb) + (data$iqrFl) + (data$iqrHg) +(data$iqrMn) + data$calories + data$sex + data$INDFMPIR_ts + data$age + data$smoke + data$activityscore + data$sch_activityscore + data$race) cft &lt;- summary(Multiple_BMXWAIST) round(cft$coefficients[2,1],2); round(confint(Multiple_BMXWAIST), 2)[2,] ## [1] -0.31 ## 2.5 % 97.5 % ## -1.02 0.40 Longitud del brazo superior - Upper arm length Multiple_BMXARML &lt;- lm(data$BMXARML ~ (data$iqrSe) + (data$iqrPb) + (data$iqrFl) + (data$iqrHg) + (data$iqrMn) + data$calories + data$sex + data$INDFMPIR_ts + data$age + data$smoke + data$activityscore + data$sch_activityscore + data$race) cft &lt;- summary(Multiple_BMXARML) round(cft$coefficients[2,1],2); round(confint(Multiple_BMXARML), 2)[2,] ## [1] -0.07 ## 2.5 % 97.5 % ## -0.20 0.06 "],["regresión-logística.html", "Chapter 5 Regresión logística 5.1 Ejemplo", " Chapter 5 Regresión logística Acceso al código Cuando queremos evaluar la relación entre una o más variables predictoras y una variable de respuesta continua, usamos regresión lineal. La regresión logística es un método que podemos usar para ajustar un modelo de regresión cuando la variable de respuesta es binaria. Cuando ajustas un modelo de regresión logística en R, los coeficientes en el resumen del modelo representan el cambio promedio en el logaritmo de las probabilidades de la variable de respuesta asociadas con un aumento de una unidad en cada variable predictora. \\(log[p(X) / (1-p(X))] = β0 + β1X1 + β2X2 + … + βpXp\\) Xj: La j-ésima variable predictora βj: La estimación del coeficiente para la j-ésima variable predictora” 5.1 Ejemplo options(scipen=999) #Desactivar la notación científica rm(list=ls()) library(tidyverse) La base de datos Default contiene información simulada sobre diez mil clientes que nos permite predecir qué clientes incumplirán con su deuda de tarjeta de crédito. library(ISLR) names(Default) ## [1] &quot;default&quot; &quot;student&quot; &quot;balance&quot; &quot;income&quot; head(Default) #&quot;Ver las primeras cinco filas del conjunto de datos &quot; ## default student balance income ## 1 No No 729.5265 44361.625 ## 2 No Yes 817.1804 12106.135 ## 3 No No 1073.5492 31767.139 ## 4 No No 529.2506 35704.494 ## 5 No No 785.6559 38463.496 ## 6 No Yes 919.5885 7491.559 dim(Default) ## [1] 10000 4 Base de datos con 10000 observaciones en las siguientes 4 variables. default: Un factor con niveles No y Sí que indica si el cliente incumplió su deuda student: Un factor con niveles No y Sí que indica si el cliente es estudiante balance: El saldo promedio que el cliente tiene en su tarjeta de crédito después de realizar su pago mensual income: Ingresos del cliente” Default %&gt;% ggplot(aes(balance, income, color = default)) + geom_point(alpha = 0.4) + scale_color_brewer(palette = &quot;Set1&quot;, direction = -1) + labs(title = &quot;Estado de incumplimiento según ingreso y saldo.&quot;) Con la evaluación gráfica parece que “balance” es un mejor predictor de “default” que “income”. p1 &lt;- Default %&gt;% ggplot(aes(income, default, fill = student)) + geom_boxplot(alpha = 0.8) + scale_fill_brewer(palette = &quot;Dark2&quot;) + labs(title = &quot;Distribution of default&quot;, subtitle = &quot;by balance and student status&quot;, caption = &quot;Data from ISLR package&quot;) p1 p1 &lt;- Default %&gt;% ggplot(aes(balance, default, fill = student)) + geom_boxplot(alpha = 0.8) + scale_fill_brewer(palette = &quot;Dark2&quot;) + labs(title = &quot;Distribution of default&quot;, subtitle = &quot;by balance and student status&quot;, caption = &quot;Data from ISLR package&quot;) p1 Visualización de la curva logistica Default$default_1 &lt;- as.numeric(Default$default==&quot;Yes&quot;) ggplot(data=Default, aes(y=default_1, x= balance)) + geom_point(alpha=0.2) + stat_smooth(method=&quot;glm&quot;, se=FALSE, method.args = list(family=binomial)) ## `geom_smooth()` using formula = &#39;y ~ x&#39; Utilizaremos el estado de estudiante, el saldo bancario y el ingreso para generar un modelo de regresión logística capaz de predecir la probabilidad de que un individuo dado incumpla su deuda. model &lt;- glm(default~student+balance+income, family=&#39;binomial&#39;, data=Default) #generamos el modelo de regresion logistica summary(model) #ver el modelo ## ## Call: ## glm(formula = default ~ student + balance + income, family = &quot;binomial&quot;, ## data = Default) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -10.869045196 0.492255516 -22.080 &lt; 0.0000000000000002 *** ## studentYes -0.646775807 0.236252529 -2.738 0.00619 ** ## balance 0.005736505 0.000231895 24.738 &lt; 0.0000000000000002 *** ## income 0.000003033 0.000008203 0.370 0.71152 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 2920.6 on 9999 degrees of freedom ## Residual deviance: 1571.5 on 9996 degrees of freedom ## AIC: 1579.5 ## ## Number of Fisher Scoring iterations: 8 Los coeficientes en la salida indican el cambio promedio en los logaritmos de las probabilidades de incumplimiento. Por ejemplo, un aumento de una unidad en el saldo está asociado con un aumento promedio de 0.005988 en los logaritmos de las probabilidades de incumplimiento. Para calcular el cambio la razón de probabilidades para cada variable predictora, podemos utilizar la siguiente sintaxis: exp(coef(model)) #calcular la razón de probabilidades (odd ratio) para cada variable predictora ## (Intercept) studentYes balance income ## 0.00001903854 0.52373166965 1.00575299051 1.00000303345 También podemos calcular cada razón de probabilidades junto con un intervalo de confianza del 95% para cada razón de probabilidades: exp(cbind(Odds_Ratio = coef(model), confint(model))) #calcular la razón de probabilidades y el intervalo de confianza del 95% para cada variable predictora&quot; ## Waiting for profiling to be done... ## Odds_Ratio 2.5 % 97.5 % ## (Intercept) 0.00001903854 0.000007074481 0.0000487808 ## studentYes 0.52373166965 0.329882707270 0.8334223982 ## balance 1.00575299051 1.005308940686 1.0062238757 ## income 1.00000303345 0.999986952969 1.0000191246 La razón de probabilidades para cada coeficiente representa el aumento promedio en las probabilidades de que un individuo incumpla, suponiendo que todas las demás variables predictoras se mantengan constantes. Por ejemplo, la variable predictora saldo tiene una razón de probabilidades de 1.0057. Esto significa que por cada dólar adicional en el saldo llevado por un individuo, las probabilidades de que el individuo incumpla su préstamo aumentan en un factor de 1.0057, suponiendo que el estado de estudiante y el ingreso se mantengan constantes. Podemos interpretar las razones de probabilidades para las otras variables predictoras de manera similar. "],["referencias.html", "Chapter 6 Referencias", " Chapter 6 Referencias "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
